{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import math\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Bidirectional, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex = pd.read_csv('prep_forex.csv', header=[0,1], index_col=0)\n",
    "index = pd.read_csv('prep_index.csv', header=[0,1,2], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_features = {\"BDT\": [None, \"VND\"], \n",
    "               \"MNT\": [None, \"LKR\"],\n",
    "               ('PKR', 'Karachi 100'): [None, \"INR\", ('JPY', 'NIkkei 225')],\n",
    "               ('LKR', 'CSE All-Share'): [None, \"IDR\", ('MNT', 'MNE Top 20')]}\n",
    "\n",
    "feats = [('PKR', 'Karachi 100'), ('LKR', 'CSE All-Share'), \"BDT\", \"MNT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_pairs = list(set([x[1] for x in forex.columns if x[0] == 'Close']))\n",
    "index_pairs = list(set([(x[1], x[2]) for x in index.columns if x[0] == 'Close']))\n",
    "\n",
    "scalers = [None, MinMaxScaler, MaxAbsScaler, StandardScaler, RobustScaler, Normalizer,\n",
    "           QuantileTransformer, PowerTransformer, FunctionTransformer]\n",
    "\n",
    "metric = 'Close'\n",
    "metrics = ['Open', 'Close', 'Low', 'High', 'Volume']\n",
    "# target = [metric]\n",
    "features = ['Intraday_OC', 'Prev_close_open'] + [y+x for x in ['', '_Ret', '_MTD', '_YTD'] for y in metrics]# if (x+y) not in target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_true, y_pred, model):\n",
    "    plot_df = pd.concat([pd.DataFrame(y_true), pd.DataFrame(y_pred)], axis=1, ignore_index=True)\n",
    "    plt.figure()\n",
    "    plt.plot(plot_df)\n",
    "    plt.title(\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scale(X, y, scaler):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "    if(scaler):\n",
    "        scaler_X = scaler()\n",
    "        if(scaler == scalers[-1]):\n",
    "            scaler_X = scaler(np.log1p)\n",
    "        scaler_X = scaler_X.fit(X_train)\n",
    "        X_train = scaler_X.transform(X_train)\n",
    "        X_test = scaler_X.transform(X_test)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bins(real, pred):\n",
    "    try:\n",
    "        y_test = Binarizer().transform(pd.DataFrame(real).pct_change().dropna())\n",
    "        y_pred = Binarizer().transform(pd.DataFrame(pred).pct_change().dropna())\n",
    "    except:\n",
    "        y_test = Binarizer().transform(pd.DataFrame(real))\n",
    "        y_pred = Binarizer().transform(pd.DataFrame(pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return({\"F1\" :f1_score(y_test, y_pred, average='weighted'),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(real, pred, extra_feat, is_exog):\n",
    "    save_data = pd.DataFrame(columns = ['y_true_class', 'y_pred_class', 'y_true_reg', 'y_pred_reg'], index = real.index)\n",
    "    save_data['y_true_reg'] = real.values\n",
    "    save_data['y_pred_reg'] = pred\n",
    "    if(metric[-3:] == 'Ret'):\n",
    "        save_data['y_true_class'] = np.sign(save_data['y_true_reg'])\n",
    "        save_data['y_pred_class'] = np.sign(save_data['y_pred_reg'])\n",
    "    else:\n",
    "        save_data['y_true_class'] = np.sign(save_data['y_true_reg'].pct_change())\n",
    "        save_data['y_pred_class'] = np.sign(save_data['y_pred_reg'].pct_change())\n",
    "    try:\n",
    "        save_data.to_csv(real.columns[0][1]+\"_\"+real.columns[0][0]+\"_\"+str(extra_feat)+\"_\"+str(is_exog)+\"_LSTM.csv\")\n",
    "    except:\n",
    "        save_data.to_csv(real.columns[0][1]+\"_\"+real.columns[0][0]+\"_\"+str(is_exog)+\"_LSTM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cross_domain_features(feat):\n",
    "    if(isinstance(feat, tuple)):\n",
    "        index_cols = index_cols = [x for x in index.columns if x[1] == feat[0] and x[2] == feat[1]]\n",
    "        X = index[[col for col in index_cols if col[0] in features + ['Time features']]][:-1]\n",
    "    else:\n",
    "        forex_cols = [x for x in forex.columns if x[1] == feat]\n",
    "        X = forex[[col for col in forex_cols if col[0] in features + ['Time features']]][:-1]\n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forex_lstm(cur, target, extra_feat, is_exog=False, transf = None):\n",
    "    forex_cols = [x for x in forex.columns if x[1] == cur]\n",
    "    X = forex[[col for col in forex_cols if col[0] in features + ['Time features']]][:-1]\n",
    "    y = forex[[col for col in forex_cols if col[0] == metric]].shift(-1)[:-1]\n",
    "    if(extra_feat):\n",
    "            X = X.join(add_cross_domain_features(extra_feat))\n",
    "    X = X.dropna(how='all', axis=1)\n",
    "    X = X.dropna(how='any')\n",
    "    y = y[y.index.isin(X.index)]\n",
    "    X_train, X_test, y_train, y_test = split_scale(X, y, transf)\n",
    "    res, y_pred = run_lstm_model((X_train, y_train), (X_test, y_test), is_exog)\n",
    "    save_to_csv(y_test, y_pred, extra_feat, is_exog)\n",
    "    metrics = check_bins(y_test, y_pred)\n",
    "    res.update(metrics)\n",
    "    return(res)\n",
    "\n",
    "def do_index_lstm(cur, target, extra_feat, is_exog=False, transf = None):\n",
    "    index_cols = [x for x in index.columns if x[1] == cur[0] and x[2] == cur[1]]\n",
    "    X = index[[col for col in index_cols if col[0] in features + ['Time features']]][:-1]\n",
    "    y = index[[col for col in index_cols if col[0] == metric]].shift(-1)[:-1]\n",
    "    if(extra_feat):\n",
    "            X = X.join(add_cross_domain_features(extra_feat))\n",
    "    X = X.dropna(how='all', axis=1)\n",
    "#     X = X.dropna(how='any')\n",
    "    y = y[y.index.isin(X.index)]\n",
    "    pd.concat([X, y], axis=1).to_csv(\"just_checking.csv\")\n",
    "    X_train, X_test, y_train, y_test = split_scale(X, y, transf)\n",
    "    res, y_pred = run_lstm_model((X_train, y_train), (X_test, y_test), is_exog)\n",
    "    save_to_csv(y_test, y_pred, extra_feat, is_exog)\n",
    "    metrics = check_bins(y_test, y_pred)\n",
    "    return(res.update(metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_model(train, test, is_exog=False):\n",
    "    train_X, train_y = train\n",
    "    test_X, test_y = test\n",
    "    if(not is_exog):\n",
    "        X_train = None\n",
    "    train_X = train_X.values.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.values.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100,kernel_initializer='random_uniform', input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "#     model.add(LSTM(100))\n",
    "    model.add(Dense(100))\n",
    "#     model.add(Dense(50))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=128, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # plot history\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    # invert scaling for forecast\n",
    "    yhat = yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.values.reshape((len(test_y), 1))\n",
    "    test_y = test_y[:,0]\n",
    "    # calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(test_y, yhat))\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    print('Test R2: %.3f' % r2_score(test_y, yhat))\n",
    "    plot_results(test_y, yhat, model)\n",
    "    return({}, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2085, 1, 20) (2085, 1) (522, 1, 20) (522, 1)\n",
      "Train on 2085 samples, validate on 522 samples\n",
      "Epoch 1/50\n",
      " - 14s - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 11/50\n",
      " - 0s - loss: nan - val_loss: nan\n",
      "Epoch 12/50\n"
     ]
    }
   ],
   "source": [
    "for cur in feats:\n",
    "    for extra_feat in cd_features[cur]:\n",
    "        for is_exog in [True, False]:\n",
    "            do_index_lstm(cur, metric, extra_feat, is_exog=is_exog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
